{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Kalapa Challenges - Vietnamese Medical Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing library packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Corpus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 603\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"../corpus\")\n",
    "corpus = []\n",
    "\n",
    "# Preprocessing corpus dataset (remove html tags, links, unnecessary characters, ...)\n",
    "if not os.path.exists(\"../preprocessed_corpus\"):\n",
    "    os.makedirs(\"../preprocessed_corpus\")\n",
    "for file in files:\n",
    "    dat = \"\"\n",
    "    with open(\"../corpus/\" + file, \"r\") as f:\n",
    "        data = f.read()\n",
    "        dat = re.sub(\"(<\\S+>)\", \"\" ,data)\n",
    "        dat = re.sub(\"(^https?:\\/\\/\\S+)\", \"\", dat)\n",
    "        dat = dat.replace(\">\", \"\")\n",
    "        corpus.append(dat)\n",
    "        \n",
    "    with open(\"../preprocessed_corpus/\" + file, \"w\") as f:\n",
    "        f.write(dat)\n",
    "    \n",
    "print(f\"Corpus size: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: (603, 874363)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF model\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0.0, stop_words = 'english')\n",
    "\n",
    "# Vectorizing the documents into sparse matrix\n",
    "tfidf_matrix =  tf.fit_transform(corpus)\n",
    "feature_names = tf.get_feature_names() \n",
    "\n",
    "# Matrix TF-IDF with each row and each colums representing each document in the corpus (disease) and word phrase extracted from the corpus\n",
    "print(f\"Vector shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Convert the sparse matrix into complete matrix\n",
    "dense = tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer sample: ['Vi khuẩn lậu' 'Chlamydia' 'Không có tác nhân nào gây ra']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "test = pd.read_csv(\"../public_test.csv\")\n",
    "\n",
    "# Make list of all the options of all questions\n",
    "cols = [col for col in test.columns if \"option\" in col]\n",
    "# Remove options with nan valuesP\n",
    "raw_options = []\n",
    "for index, row in test[cols].iterrows():\n",
    "    raw_options.append(row.dropna().values)\n",
    "\n",
    "def process_element(element):\n",
    "    return np.array([re.sub(r'^[A-Z]\\.', '', item).strip() for item in element], dtype='object')\n",
    "\n",
    "options = [process_element(item) for item in raw_options]\n",
    "print(f\"Answer sample: {options[np.random.randint(0, len(options))]}\")\n",
    "\n",
    "# Vectorize list of questions into matrix with each row having the same length as the vectorized corpus matrix\n",
    "question_vec = test[\"question\"].apply(lambda x: tf.transform([x]).todense()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "idx_ls = []\n",
    "# Find the most similar document in the corpus for each question represented as the index of the word phrase with the highest score\n",
    "for question in tqdm(question_vec):\n",
    "    idx_ls.append(linear_kernel(question, dense).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "\n",
    "    def __init__(self, k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        \"\"\"\n",
    "        Fit the various statistics that are required to calculate BM25 ranking\n",
    "        score using the corpus given.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : list[list[str]]\n",
    "            Each element in the list represents a document, and each document\n",
    "            is a list of the terms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        tf = []\n",
    "        df = {}\n",
    "        idf = {}\n",
    "        doc_len = []\n",
    "        corpus_size = 0\n",
    "        for document in corpus:\n",
    "            corpus_size += 1\n",
    "            doc_len.append(len(document))\n",
    "\n",
    "            # compute tf (term frequency) per document\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                term_count = frequencies.get(term, 0) + 1\n",
    "                frequencies[term] = term_count\n",
    "\n",
    "            tf.append(frequencies)\n",
    "\n",
    "            # compute df (document frequency) per term\n",
    "            for term, _ in frequencies.items():\n",
    "                df_count = df.get(term, 0) + 1\n",
    "                df[term] = df_count\n",
    "\n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "\n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.corpus_ = corpus\n",
    "        self.corpus_size_ = corpus_size\n",
    "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
    "        return self\n",
    "\n",
    "    def search(self, query):\n",
    "        scores = [self._score(query, index) for index in range(self.corpus_size_)]\n",
    "        return scores\n",
    "\n",
    "    def _score(self, query, index):\n",
    "        score = 0.0\n",
    "\n",
    "        doc_len = self.doc_len_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        for term in query:\n",
    "            if term not in frequencies:\n",
    "                continue\n",
    "\n",
    "            freq = frequencies[term]\n",
    "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
    "            denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len_)\n",
    "            score += (numerator / denominator)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm \n",
    "\n",
    "def inference(idx_ls, test, corpus, retrieval_model, embedding_model, segementing_model, k:int=5):\n",
    "    res = {\"id\": [],\n",
    "           \"answer\": []}\n",
    "    \n",
    "    for i in tqdm(range(len(idx_ls))):\n",
    "        # Get the index of the document in the corpus for the corresponding question\n",
    "        idx = idx_ls[i]\n",
    "        # print(f\"Question: {idx}\")\n",
    "        \n",
    "        question = test[\"question\"][i]\n",
    "        # print(\"question: \", question)\n",
    "        # print(\"options: \", options[i])\n",
    "        \n",
    "        # Tokenize the document\n",
    "        sentences_list = corpus[idx].replace(\"\\n\", \" \").split(\". \")\n",
    "        words_lists = [[word for word in sentence.lower().split()] for sentence in sentences_list]\n",
    "        \n",
    "        # Fit BM25 model to the document\n",
    "        retrieval_model.fit(words_lists)\n",
    "\n",
    "        # Split question into sequence of single words\n",
    "        query = question.split()\n",
    "\n",
    "        # Score each preprocessed sentence in the selected document above\n",
    "        scores = retrieval_model.search(query)\n",
    "        # Sort the score list in descending order\n",
    "        scores_index = np.argsort(scores)[::-1]\n",
    "\n",
    "        # Get top k sentences (the top candidate in the list order is yet to be the best sentence)\n",
    "        top_k = np.array([sentences_list[i] for i in scores_index])[:k]\n",
    "\n",
    "        # Segmenting sentences of top k candidates, questions, and options\n",
    "        segmented_top_k = []\n",
    "        for sentence in top_k:\n",
    "            segmented_sentence = segementing_model.word_segment(sentence)\n",
    "            segmented_top_k.append(\" \".join(segmented_sentence))\n",
    "\n",
    "        segmented_question = \" \".join(segementing_model.word_segment(question))\n",
    "\n",
    "        segmented_options = []\n",
    "        for option in options[i]:\n",
    "            segmented_option = segementing_model.word_segment(option)\n",
    "            segmented_options.append(\" \".join(segmented_option))\n",
    "        \n",
    "        # Word embedding for top candidates\n",
    "        top_k_embedding = np.zeros((len(segmented_top_k), 768))\n",
    "        for index, segmented_sentence in enumerate(segmented_top_k):\n",
    "            top_k_embedding[index] = embedding_model.encode(segmented_sentence)\n",
    "        \n",
    "        # Word embedding for question\n",
    "        query = embedding_model.encode(segmented_question)\n",
    "\n",
    "        # Word embedding for options\n",
    "        options_embedding = np.zeros((len(segmented_options), 768))\n",
    "        for index, segmented_option in enumerate(segmented_options):\n",
    "            options_embedding[index] = embedding_model.encode(segmented_option)\n",
    "        \n",
    "        # Calculate similarity level between queries and embedding of top candidate sentences\n",
    "        idx = cosine_similarity([query], top_k_embedding).argmax()\n",
    "        # Get the final sentence in the top k candidates with the most similarity to the query\n",
    "        answer = segmented_top_k[idx]\n",
    "        \n",
    "        # Calculate similarity level between options and the final sentence to choose the the final option for the query\n",
    "        scores = cosine_similarity(np.array([embedding_model.encode(answer)]), options_embedding) \n",
    "        max_idx = scores.argmax()\n",
    "        \n",
    "        predictions = np.zeros(scores.shape[1], dtype=int)\n",
    "        \n",
    "        predictions[max_idx] = 1\n",
    "        \n",
    "        res[\"id\"].append(test[\"id\"][i])\n",
    "        res[\"answer\"].append(\"\".join([str(pred) for pred in predictions]))\n",
    "        \n",
    "        # print(f\"Reference: {answer}\")\n",
    "        # print(f\"Answer: {options[i][max_idx]}\")\n",
    "        \n",
    "    df = pd.DataFrame(columns=['id', 'answer'], data=res)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-29 14:24:20 INFO  WordSegmenter:24 - Loading Word Segmentation model\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "retrieval_model = BM25()\n",
    "embedding_model = SentenceTransformer('bkai-foundation-models/vietnamese-bi-encoder', cache_folder=\"./cache\")\n",
    "\n",
    "import py_vncorenlp\n",
    "# py_vncorenlp.download_model(save_dir='./cache/vncorenlp')\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/space/hotel/taile/kalapa/src/cache/vncorenlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>level3_1</td>\n",
       "      <td>0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>level3_2</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>level3_5</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>level3_13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>level3_14</td>\n",
       "      <td>0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>level4_4</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>level4_9</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>level4_27</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>level4_28</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>level4_35</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id answer\n",
       "0    level3_1   0100\n",
       "1    level3_2   0010\n",
       "2    level3_5   0010\n",
       "3   level3_13     10\n",
       "4   level3_14   0100\n",
       "..        ...    ...\n",
       "95   level4_4   1000\n",
       "96   level4_9   0010\n",
       "97  level4_27   0001\n",
       "98  level4_28   1000\n",
       "99  level4_35    010\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = inference(idx_ls, test, corpus, retrieval_model, embedding_model, rdrsegmenter)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/space/hotel/taile/kalapa/src/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
